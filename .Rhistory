print("hello")
library(readr)  # For reading CSV files
library(dplyr)  # For data manipulation
library(lubridate)  # For date parsing
library(tseries)
library(vars)
library(forecast)
library(urca)
library(tsDyn)
library(tidyverse)
library(tempdisagg)
library(xts)
library(tsbox)
library(data.table)
library(progress)
library(MTS)
library(BVAR)
library(psych)
library(ggplot2)
# STEP 1: READ CSV
spot <- read_delim('./data/spot/clarkson_data.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d/%m/%Y")),
trim_ws = TRUE)
#getwd()
setwd("./VSCode/master-thesis")
#setwd("./master-thesis")
library(readr)  # For reading CSV files
library(dplyr)  # For data manipulation
library(lubridate)  # For date parsing
library(tseries)
library(vars)
library(forecast)
library(urca)
library(tsDyn)
library(tidyverse)
library(tempdisagg)
library(xts)
library(tsbox)
library(data.table)
library(progress)
library(MTS)
library(BVAR)
library(psych)
library(ggplot2)
# STEP 1: READ CSV
spot <- read_delim('./data/spot/clarkson_data.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d/%m/%Y")),
trim_ws = TRUE)
pmx_forw <- read_delim('./data/ffa/PMAX_FFA.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
csz_forw <- read_delim('./data/ffa/CSZ_FFA.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
smx_forw <- read_delim('./data/ffa/SMX_FFA.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
# Macro data is reading nicely now
gbti_dev <- read_csv('./data/other/gbti_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
oecd_ip_dev <- read_csv('./data/other/oecd_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
fleet_age <- read_csv('./data/other/fleet_age_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
fleet_dev <- read_csv('./data/other/fleet_dev_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
orderbook <- read_csv('./data/other/orderbook_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
steel_prod <- read_csv('./data/other/steel_prod_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
vessel_sale_volume <- read_csv('./data/other/vessel_sale_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
eur_usd <- read_delim('./data/other/EUR_USD_historical.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
sp500 <- read_delim('./data/other/sp500.csv',
delim = ',',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d-%b-%Y")),
trim_ws = TRUE)
bdi <- read_delim('./data/spot/clarkson_data.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d/%m/%Y")),
trim_ws = TRUE)
# Convert columns from text to numeric, replacing commas with dots
eur_usd <- eur_usd %>%
mutate(across(-Date, ~as.numeric(gsub(",", ".", .x))))
sp500 <- sp500 %>%
mutate(across(-Date, ~as.numeric(gsub(",", ".", .x))))
bdi <- bdi %>%
mutate(across(-Date, ~as.numeric(gsub(",", ".", .x))))
# STEP 2: CLEAN AND PREPARE DATA
# CSZ column: CSZ
# PMX column: PMX
# SMX column: SMX
# ffa column: 1MON, 1Q
# Merge data frames on the Date column, include trade volume
#data_combined <- merge(spot, csz_forw, by = "Date")
#data_combined <- merge(data_combined, gbti_dev, by = "Date")
####### ENDRE ######
data_combined <- inner_join(spot[, c("Date", "CSZ")], csz_forw[, c("Date", "1MON")], by = "Date")
data_ID <- list("CSZ", "1REG")
####### ENDRE ######
#data_combined <- inner_join(data_combined, gbti_dev[, c("Date", "Iron Ore Trade Vol", "Coal Trade Vol", "Grain Trade Vol", "Minor Bulk Trade Vol", "Dry Bulk Trade Vol")], by = "Date")
#data_combined <- inner_join(data_combined, oecd_ip_dev[, c("Date", "Ind Prod Excl Const VOLA")], by = "Date")
#data_combined <- inner_join(data_combined, fleet_dev[, c("Date", "HSZ fleet", "HMX fleet", "PMX fleet", "CSZ fleet")], by = "Date")
#data_combined <- inner_join(data_combined, fleet_dev[, c("Date", "PMX fleet")], by = "Date")
data_combined <- inner_join(data_combined, eur_usd[, c("Date", "Last")], by = "Date")
data_combined <- inner_join(data_combined, sp500[, c("Date", "Close")], by = "Date")
data_combined <- inner_join(data_combined, bdi[, c("Date", "BDI")], by = "Date")
# Removing rows where ColumnA or ColumnB have 0 or NA values
data_combined <- data_combined %>%
filter(if_all(-Date, ~ .x != 0 & !is.na(.x)))
# Remove rows with NA or 0 in either the S6TC_S10TC column or the 4TC_ROLL column
#data_combined <- subset(data_combined, !(is.na(CSZ) | CSZ == 0) & !(is.na(`CURMON`) | `CURMON` == 0))
# Transform data to log levels and create a new data frame for log levels
data_log_levels <- data.frame(
Date = data_combined$Date,
####### ENDRE ######
spot = log(data_combined$CSZ),
forwp = log(data_combined$`1MON`)
####### ENDRE ######
)
#exog_log_levels <- data.frame(
#  Date = data_combined$Date,
#  iron = log(data_combined$`Iron Ore Trade Vol`),  # Assuming you meant to log-transform these as well
#  coal = log(data_combined$`Coal Trade Vol`),
#  grain = log(data_combined$`Grain Trade Vol`),
#  minor_bulk = log(data_combined$`Minor Bulk Trade Vol`),
#  dry_bulk = log(data_combined$`Dry Bulk Trade Vol`),
#  eur_usd = data_combined$Last  # Not log-transformed as it's a rate, but adjust according to your needs
#)
exog_log_levels <- data.frame(
Date = data_combined$Date,
#ind_prod = log(data_combined$`Ind Prod Excl Const VOLA`),  # Assuming you meant to log-transform these as well
#hsz_dev = log(data_combined$`HSZ fleet`),
#hmx_dev = log(data_combined$`HMX fleet`),
#pmx_dev = log(data_combined$`PMX fleet`),
#csz_dev = log(data_combined$`PMX fleet`),
eur_usd = data_combined$Last  # Not log-transformed as it's a rate, but adjust according to your needs,
#sp500 = log(data_combined$Close)
#bdi = log(data_combined$BDI)
#iron = log(data_combined$`Iron Ore Trade Vol`),
#coal = log(data_combined$`Coal Trade Vol`)
)
######## ENDRE ###########
#data_combined <- data_combined[1:579, ]
#data_log_levels <- data_log_levels[1:579, ]
data_combined <- data_combined[580:1971, ]
data_log_levels <- data_log_levels[580:1971, ]
# Display the first few rows of each new data frame to verify
print(head(data_log_levels))
# Calculate the index for the split
split_index <- floor(nrow(data_combined) * 0.8)
# Split the data into training and test sets
train_lev <- data_log_levels[1:split_index, ]
#getwd()
#setwd("./VSCode/master-thesis")
#setwd("./master-thesis")
library(readr)  # For reading CSV files
library(dplyr)  # For data manipulation
library(lubridate)  # For date parsing
library(tseries)
library(vars)
library(forecast)
library(urca)
library(tsDyn)
library(tidyverse)
library(tempdisagg)
library(xts)
library(tsbox)
library(data.table)
library(progress)
library(MTS)
library(BVAR)
library(psych)
library(ggplot2)
# STEP 1: READ CSV
spot <- read_delim('./data/spot/clarkson_data.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d/%m/%Y")),
trim_ws = TRUE)
pmx_forw <- read_delim('./data/ffa/PMAX_FFA.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
csz_forw <- read_delim('./data/ffa/CSZ_FFA.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
smx_forw <- read_delim('./data/ffa/SMX_FFA.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
# Macro data is reading nicely now
gbti_dev <- read_csv('./data/other/gbti_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
oecd_ip_dev <- read_csv('./data/other/oecd_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
fleet_age <- read_csv('./data/other/fleet_age_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
fleet_dev <- read_csv('./data/other/fleet_dev_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
orderbook <- read_csv('./data/other/orderbook_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
steel_prod <- read_csv('./data/other/steel_prod_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
vessel_sale_volume <- read_csv('./data/other/vessel_sale_daily.csv',
col_types = cols(Date = col_date(format = "%d-%m-%Y")),
trim_ws = TRUE)
eur_usd <- read_delim('./data/other/EUR_USD_historical.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d.%m.%Y")),
trim_ws = TRUE)
sp500 <- read_delim('./data/other/sp500.csv',
delim = ',',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d-%b-%Y")),
trim_ws = TRUE)
bdi <- read_delim('./data/spot/clarkson_data.csv',
delim = ';',
escape_double = FALSE,
col_types = cols(Date = col_date(format = "%d/%m/%Y")),
trim_ws = TRUE)
# Convert columns from text to numeric, replacing commas with dots
eur_usd <- eur_usd %>%
mutate(across(-Date, ~as.numeric(gsub(",", ".", .x))))
sp500 <- sp500 %>%
mutate(across(-Date, ~as.numeric(gsub(",", ".", .x))))
bdi <- bdi %>%
mutate(across(-Date, ~as.numeric(gsub(",", ".", .x))))
# STEP 2: CLEAN AND PREPARE DATA
# CSZ column: CSZ
# PMX column: PMX
# SMX column: SMX
# ffa column: 1MON, 1Q
# Merge data frames on the Date column, include trade volume
#data_combined <- merge(spot, csz_forw, by = "Date")
#data_combined <- merge(data_combined, gbti_dev, by = "Date")
####### ENDRE ######
data_combined <- inner_join(spot[, c("Date", "CSZ")], csz_forw[, c("Date", "1MON")], by = "Date")
data_ID <- list("CSZ", "1REG")
####### ENDRE ######
#data_combined <- inner_join(data_combined, gbti_dev[, c("Date", "Iron Ore Trade Vol", "Coal Trade Vol", "Grain Trade Vol", "Minor Bulk Trade Vol", "Dry Bulk Trade Vol")], by = "Date")
#data_combined <- inner_join(data_combined, oecd_ip_dev[, c("Date", "Ind Prod Excl Const VOLA")], by = "Date")
#data_combined <- inner_join(data_combined, fleet_dev[, c("Date", "HSZ fleet", "HMX fleet", "PMX fleet", "CSZ fleet")], by = "Date")
#data_combined <- inner_join(data_combined, fleet_dev[, c("Date", "PMX fleet")], by = "Date")
data_combined <- inner_join(data_combined, eur_usd[, c("Date", "Last")], by = "Date")
data_combined <- inner_join(data_combined, sp500[, c("Date", "Close")], by = "Date")
data_combined <- inner_join(data_combined, bdi[, c("Date", "BDI")], by = "Date")
# Removing rows where ColumnA or ColumnB have 0 or NA values
data_combined <- data_combined %>%
filter(if_all(-Date, ~ .x != 0 & !is.na(.x)))
# Remove rows with NA or 0 in either the S6TC_S10TC column or the 4TC_ROLL column
#data_combined <- subset(data_combined, !(is.na(CSZ) | CSZ == 0) & !(is.na(`CURMON`) | `CURMON` == 0))
# Transform data to log levels and create a new data frame for log levels
data_log_levels <- data.frame(
Date = data_combined$Date,
####### ENDRE ######
spot = log(data_combined$CSZ),
forwp = log(data_combined$`1MON`)
####### ENDRE ######
)
#exog_log_levels <- data.frame(
#  Date = data_combined$Date,
#  iron = log(data_combined$`Iron Ore Trade Vol`),  # Assuming you meant to log-transform these as well
#  coal = log(data_combined$`Coal Trade Vol`),
#  grain = log(data_combined$`Grain Trade Vol`),
#  minor_bulk = log(data_combined$`Minor Bulk Trade Vol`),
#  dry_bulk = log(data_combined$`Dry Bulk Trade Vol`),
#  eur_usd = data_combined$Last  # Not log-transformed as it's a rate, but adjust according to your needs
#)
exog_log_levels <- data.frame(
Date = data_combined$Date,
#ind_prod = log(data_combined$`Ind Prod Excl Const VOLA`),  # Assuming you meant to log-transform these as well
#hsz_dev = log(data_combined$`HSZ fleet`),
#hmx_dev = log(data_combined$`HMX fleet`),
#pmx_dev = log(data_combined$`PMX fleet`),
#csz_dev = log(data_combined$`PMX fleet`),
eur_usd = data_combined$Last  # Not log-transformed as it's a rate, but adjust according to your needs,
#sp500 = log(data_combined$Close)
#bdi = log(data_combined$BDI)
#iron = log(data_combined$`Iron Ore Trade Vol`),
#coal = log(data_combined$`Coal Trade Vol`)
)
######## ENDRE ###########
data_combined <- data_combined[1:579, ]
data_log_levels <- data_log_levels[1:579, ]
View(data_log_levels)
# Split into train and test sets
# Calculate the index for the split
split_index <- floor(nrow(data_combined) * 0.8)
# Split the data into training and test sets
train_lev <- data_log_levels[1:split_index, ]
View(train_lev)
#getwd()
#setwd("./VSCode/master-thesis")
setwd("./master-thesis")
#getwd()
setwd("./VSCode/master-thesis")
getwd()
getwd()
#getwd()
setwd("./VSCode/master-thesis")
