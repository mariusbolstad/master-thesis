{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spot = pd.read_csv('./data/spot/clarkson_data.csv', delimiter=';', parse_dates=['Date'], dayfirst=True)\n",
    "pmx_forw = pd.read_csv('./data/ffa/PMAX_FFA.csv', delimiter=';', parse_dates=['Date'], dayfirst=True)\n",
    "csz_forw = pd.read_csv('./data/ffa/CSZ_FFA.csv', delimiter=';', parse_dates=['Date'], dayfirst=True)\n",
    "smx_forw = pd.read_csv('./data/ffa/SMX_FFA.csv', delimiter=';', parse_dates=['Date'], dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m data_log_levels\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m data_combined[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Split into train and test sets\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m split_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_log_levels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m hor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m     22\u001b[0m train \u001b[38;5;241m=\u001b[39m data_log_levels\u001b[38;5;241m.\u001b[39miloc[:split_index]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Merge data frames on the Date column\n",
    "data_combined = pd.merge(spot, smx_forw, on='Date')\n",
    "s_col = \"SMX\"\n",
    "f_col = \"1Q\"\n",
    "\n",
    "# Remove rows with NA or 0 in specific columns (assuming 'SMX' and '1Q' are column names in 'data_combined')\n",
    "data_combined = data_combined[(data_combined[s_col].notna() & data_combined[s_col] != 0) & (data_combined[f_col].notna() & data_combined[f_col] != 0)]\n",
    "\n",
    "# Transform data to log levels\n",
    "data_log_levels = pd.DataFrame()\n",
    "data_log_levels[\"spot\"] = np.log(data_combined[s_col])\n",
    "data_log_levels[\"forwp\"] = np.log(data_combined[f_col])\n",
    "data_log_levels.index = data_combined[\"Date\"]\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "split_index = round(len(data_log_levels) * 0.8)\n",
    "hor = 30\n",
    "train = data_log_levels.iloc[:split_index]\n",
    "test = data_log_levels.iloc[split_index:split_index+hor]\n",
    "#train.head()\n",
    "data_log_levels.head()\n",
    "train.head()\n",
    "#test.head()\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "train_scal = scaler.fit_transform(train)\n",
    "print(train_scal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=10, is_test=False):\n",
    "    X, Y = [], []\n",
    "    if is_test:  # for test data, we just need the last entry for 1-step ahead forecast\n",
    "        X = dataset[-1:,:,]\n",
    "        return X, None\n",
    "    else:\n",
    "        for i in range(look_back, len(dataset)- hor + 1):\n",
    "            X.append(dataset[i-look_back:i])\n",
    "            Y.append(dataset[i:i+hor])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 20  # Adjust based on your temporal structure\n",
    "trainX, trainY = create_dataset(train_scal, look_back)\n",
    "print(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the MLP model\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "trainX_flat = trainX.reshape(trainX.shape[0], -1)\n",
    "trainY_flat = trainY.reshape(trainY.shape[0], -1)\n",
    "\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Dense(32, input_dim=trainX_flat.shape[1], activation='relu'))\n",
    "model_mlp.add(Dense(trainY_flat.shape[1], activation=\"linear\"))\n",
    "model_mlp.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_mlp.fit(trainX_flat, trainY_flat, epochs=1000, batch_size=2, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "trainPredict_scal_flat = model_mlp.predict(trainX_flat)\n",
    "\n",
    "\n",
    "def create_even_odd_array(arr):\n",
    "    \"\"\"\n",
    "    Returns an array where the first column contains values from even positions\n",
    "    and the second column contains values from odd positions of the original array.\n",
    "    \"\"\"\n",
    "    return arr.reshape(-1, 2)\n",
    "\n",
    "\n",
    "\n",
    "testX, _ = create_dataset(trainX, look_back=look_back, is_test=True)\n",
    "testX_flat = testX.reshape(testX.shape[0], -1)\n",
    "testPredict_scal_flat = model_mlp.predict(testX_flat)\n",
    "testPredict_scal = create_even_odd_array(testPredict_scal_flat)\n",
    "\n",
    "\n",
    "# Invert predictions\n",
    "#trainPredict = scaler.inverse_transform(trainPredict_scal)\n",
    "testPredict = scaler.inverse_transform(testPredict_scal)\n",
    "print(testPredict[:, 0])\n",
    "\n",
    "# Calculate mean squared error\n",
    "testScore = mean_squared_error(test[\"spot\"], testPredict[:,0])\n",
    "testScoreForw = mean_squared_error(test[\"forwp\"], testPredict[:,1])\n",
    "print('Test Score spot: %.5f MSE' % (testScore))\n",
    "print('Test Score forw: %.5f MSE' % (testScoreForw))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def random_walk_predictions(training_data, testing_data):\n",
    "    \"\"\"\n",
    "    Generates Random Walk predictions where the next value is assumed to be the last observed value.\n",
    "    \n",
    "    Parameters:\n",
    "    - training_data: DataFrame containing the training data.\n",
    "    - testing_data: DataFrame containing the test data.\n",
    "    \n",
    "    Returns:\n",
    "    - predictions: Numpy array containing Random Walk predictions for the test set.\n",
    "    \"\"\"\n",
    "    # Last observed values from the training set\n",
    "    last_observed_spot = training_data['spot'].iloc[-1]\n",
    "    last_observed_forwp = training_data['forwp'].iloc[-1]\n",
    "    \n",
    "    # Create an array of predictions, each one equal to the last observed values\n",
    "    predictions = np.tile([last_observed_spot, last_observed_forwp], (len(testing_data), 1))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Generate Random Walk predictions for the test set\n",
    "rw_predictions = random_walk_predictions(train, test)\n",
    "\n",
    "# Benchmark Random Walk model by calculating the MSE\n",
    "rw_testScore_spot = mean_squared_error(test[\"spot\"].values, rw_predictions[:, 0])\n",
    "rw_testScore_forw = mean_squared_error(test[\"forwp\"].values, rw_predictions[:, 1])\n",
    "\n",
    "print('Random Walk Test Score spot: %.5f MSE' % (rw_testScore_spot))\n",
    "print('Random Walk Test Score forw: %.5f MSE' % (rw_testScore_forw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model_lstm.add(LSTM(units=50))\n",
    "model_lstm.add(Dense(trainY_flat.shape[1], activation='linear'))  # Assuming multi-step forecasting\n",
    "\n",
    "model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_lstm.fit(trainX, trainY_flat, epochs=100, batch_size=32, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the last sequence from the training set as the input for the first prediction\n",
    "testX_last_sequence = train_scal[-look_back:].reshape(1, look_back, train_scal.shape[1])\n",
    "\n",
    "# Make predictions\n",
    "testPredict_scal_flat = model_lstm.predict(testX_last_sequence)\n",
    "\n",
    "# Since you're predicting `hor` steps ahead, you might need to adjust the code to generate\n",
    "# multiple steps if your LSTM model is set up for single-step predictions.\n",
    "# For simplicity, this example directly uses the LSTM output for multi-step predictions.\n",
    "\n",
    "# Invert scaling\n",
    "testPredict_scal = create_even_odd_array(testPredict_scal_flat)\n",
    "testPredict = scaler.inverse_transform(testPredict_scal)\n",
    "\n",
    "\n",
    "# Calculate and print MSE for each target\n",
    "testScore_spot_lstm = mean_squared_error(test[\"spot\"].iloc[:hor].values, testPredict[:,0])\n",
    "testScore_forw_lstm = mean_squared_error(test[\"forwp\"].iloc[:hor].values, testPredict[:,1])\n",
    "print('LSTM Test Score spot: %.5f MSE' % (testScore_spot_lstm))\n",
    "print('LSTM Test Score forw: %.5f MSE' % (testScore_forw_lstm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Number of rounds based on the test set size and forecast horizon\n",
    "num_rounds =  30  # Adjusted to ensure we don't exceed the test set\n",
    "look_back = 10  # Adjust based on your temporal structure\n",
    "hor = 5\n",
    "\n",
    "# Initialize dictionary to store MSE results for each model\n",
    "mse_results = {\n",
    "    'MLP_spot': [],\n",
    "    'MLP_forwp': [],\n",
    "    'LSTM_spot': [],\n",
    "    'LSTM_forwp': [],\n",
    "    'RW_spot': [],\n",
    "    'RW_forwp': [],\n",
    "}\n",
    "\n",
    "\n",
    "def create_even_odd_array(arr):\n",
    "    \"\"\"\n",
    "    Returns an array where the first column contains values from even positions\n",
    "    and the second column contains values from odd positions of the original array.\n",
    "    \"\"\"\n",
    "    return arr.reshape(-1, 2)\n",
    "\n",
    "\n",
    "# Adjust train and test sets for each forecast round\n",
    "for round in range(1, num_rounds + 1):\n",
    "    print(\"Round\", round)\n",
    "    # Define new split point for each round\n",
    "    split_index = split_index + (round - 1) * hor\n",
    "    \n",
    "    # Update train and test sets\n",
    "    train = data_log_levels.iloc[:split_index]\n",
    "    test = data_log_levels.iloc[split_index:split_index+hor]\n",
    "\n",
    "    #Scale train set\n",
    "    train_scal = scaler.fit_transform(train)\n",
    "\n",
    "    trainX, trainY = create_dataset(train_scal, look_back)\n",
    "    # Create and fit the MLP model\n",
    "\n",
    "    trainX_flat = trainX.reshape(trainX.shape[0], -1)\n",
    "    trainY_flat = trainY.reshape(trainY.shape[0], -1)\n",
    "\n",
    "    model_mlp = Sequential()\n",
    "    model_mlp.add(Dense(32, input_dim=trainX_flat.shape[1], activation='relu'))\n",
    "    model_mlp.add(Dense(trainY_flat.shape[1], activation=\"linear\"))\n",
    "    model_mlp.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_mlp.fit(trainX_flat, trainY_flat, epochs=10, batch_size=2, verbose=1)\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    trainPredict_scal_flat = model_mlp.predict(trainX_flat)\n",
    "    testX = train_scal[-look_back:].reshape(1, look_back, train_scal.shape[1])\n",
    "    #testX, _ = create_dataset(trainX, look_back=look_back, is_test=True)\n",
    "    testX_flat = testX.reshape(testX.shape[0], -1)\n",
    "    testPredict_scal_flat = model_mlp.predict(testX_flat)\n",
    "    testPredict_scal = create_even_odd_array(testPredict_scal_flat)\n",
    "\n",
    "    # Invert predictions\n",
    "    testPredict_mlp = scaler.inverse_transform(testPredict_scal)\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    testScore = mean_squared_error(test[\"spot\"], testPredict_mlp[:,0])\n",
    "    testScoreForw = mean_squared_error(test[\"forwp\"], testPredict_mlp[:,1])\n",
    "    print('Test Score spot MLP: %.5f MSE' % (testScore))\n",
    "    print('Test Score forw MLP: %.5f MSE' % (testScoreForw))\n",
    "\n",
    "\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model_lstm.add(LSTM(units=50))\n",
    "    model_lstm.add(Dense(trainY_flat.shape[1], activation='linear'))  # Assuming multi-step forecasting\n",
    "\n",
    "    model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_lstm.fit(trainX, trainY_flat, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Prepare the last sequence from the training set as the input for the first prediction\n",
    "    #testX_last_sequence = train_scal[-look_back:].reshape(1, look_back, train_scal.shape[1])\n",
    "\n",
    "    # Make predictions\n",
    "    testPredict_scal_flat = model_lstm.predict(testX)\n",
    "\n",
    "    # Since you're predicting `hor` steps ahead, you might need to adjust the code to generate\n",
    "    # multiple steps if your LSTM model is set up for single-step predictions.\n",
    "    # For simplicity, this example directly uses the LSTM output for multi-step predictions.\n",
    "\n",
    "    # Invert scaling\n",
    "    testPredict_scal = create_even_odd_array(testPredict_scal_flat)\n",
    "    testPredict_lstm = scaler.inverse_transform(testPredict_scal)\n",
    "\n",
    "\n",
    "    # Calculate and print MSE for each target\n",
    "    testScore_spot_lstm = mean_squared_error(test[\"spot\"].iloc[:hor].values, testPredict_lstm[:,0])\n",
    "    testScore_forw_lstm = mean_squared_error(test[\"forwp\"].iloc[:hor].values, testPredict_lstm[:,1])\n",
    "    print('LSTM Test Score spot: %.5f MSE' % (testScore_spot_lstm))\n",
    "    print('LSTM Test Score forw: %.5f MSE' % (testScore_forw_lstm))\n",
    "\n",
    "\n",
    "    # Random Walk Predictions for comparison\n",
    "    rw_predictions = random_walk_predictions(train, test)\n",
    "    \n",
    "    # Calculate and append MSE for each model for this round\n",
    "    mse_results['MLP_spot'].append(mean_squared_error(test[\"spot\"], testPredict_mlp[:, 0]))\n",
    "    mse_results['MLP_forwp'].append(mean_squared_error(test[\"forwp\"], testPredict_mlp[:, 1]))\n",
    "\n",
    "    mse_results['LSTM_spot'].append(mean_squared_error(test[\"spot\"], testPredict_lstm[:, 0]))\n",
    "    mse_results['LSTM_forwp'].append(mean_squared_error(test[\"forwp\"], testPredict_lstm[:, 1]))\n",
    "\n",
    "    mse_results['RW_spot'].append(mean_squared_error(test[\"spot\"], rw_predictions[:, 0]))\n",
    "    mse_results['RW_forwp'].append(mean_squared_error(test[\"forwp\"], rw_predictions[:, 1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in mse_results.items():\n",
    "    mean = sum(values) / len(values) * 100\n",
    "    print(f\"Mean for {key}: {mean}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
