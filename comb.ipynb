{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.758593271006248e-13\n",
      "0    9.818256\n",
      "1    9.824985\n",
      "2    9.852931\n",
      "3    9.851510\n",
      "4    9.819127\n",
      "Name: Actual, dtype: float64\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 506\u001b[0m\n\u001b[1;32m    504\u001b[0m avg_1_mae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(avg_1_maes)\n\u001b[1;32m    505\u001b[0m avg_1_mape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(avg_1_mapes)\n\u001b[0;32m--> 506\u001b[0m avg_1_corr_dir \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_avg_dir_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mavg_1_corr_dirs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m avg_1_red \u001b[38;5;241m=\u001b[39m calculate_rmse_reduction(rw_rmse, avg_1_rmse)\n\u001b[1;32m    509\u001b[0m eigen_1_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(eigen_1_rmses)\n",
      "Cell \u001b[0;32mIn[18], line 39\u001b[0m, in \u001b[0;36mcalculate_avg_dir_accuracy\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_avg_dir_accuracy\u001b[39m(values):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def direction_accuracy(actual, forecast):\n",
    "    actual_direction = np.sign(np.diff(actual))\n",
    "    forecast_direction = np.sign(np.diff(forecast))\n",
    "    correct = np.sum(actual_direction == forecast_direction)\n",
    "    return correct / len(actual_direction) * 100\n",
    "\n",
    "def rmse_reduction(rmse_model, rmse_rw):\n",
    "    return (1 - rmse_model / rmse_rw) * 100\n",
    "\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def calculate_corr_dir(actual_values, predicted_values, last_value):\n",
    "    if not last_value:\n",
    "        return 1\n",
    "    t = actual_values.tail(1).values[0]\n",
    "    t2 = predicted_values.tail(1).values[0]\n",
    "    sign_act = np.sign(actual_values.tail(1).values[0] - last_value)\n",
    "    sign_pred = np.sign(predicted_values.tail(1).values[0] - last_value)\n",
    "    if sign_act == sign_pred:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_avg_dir_accuracy(values):\n",
    "    return sum(values) / len(values) * 100\n",
    "\n",
    "\n",
    "def calculate_rmse_reduction(baseline_rmse, model_rmse):\n",
    "    return (baseline_rmse - model_rmse) / baseline_rmse * 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "segments = [\"csz\", \"pmx\", \"smx\"]\n",
    "horizons = [1, 2, 5, 10, 20]\n",
    "\n",
    "#segments = [\"pmx\", \"smx\"]\n",
    "#horizons = [1, 2, 5, 10, 20]\n",
    "\n",
    "for seg in segments:\n",
    "    for hor in horizons:\n",
    "        df_ml_0 = pd.read_csv(f\"./pred/{seg}_{hor}_0.csv\")\n",
    "        df_ml_1 = pd.read_csv(f\"./pred/{seg}_{hor}_1.csv\")\n",
    "        df_ml_2 = pd.read_csv(f\"./pred/{seg}_{hor}_2.csv\")\n",
    "\n",
    "        df_r = pd.read_csv(f\"./pred/{seg}_{hor}_r.csv\")\n",
    "\n",
    "        df_r.rename(columns={\"Actuals\": \"Actual\"}, inplace=True)\n",
    "        df_r.columns = df_r.columns.str.replace('_fcs', '_pred', regex=False)\n",
    "\n",
    "\n",
    "        #df_r = df_r.iloc[1:-27]\n",
    "        df_r.head()\n",
    "        '''\n",
    "        # Define a small delta\n",
    "        delta = 2e-3\n",
    "        ml_long = False\n",
    "        # Find the longer DataFrame\n",
    "        if len(df_ml_0) > len(df_r):\n",
    "            longer_df = df_ml_0\n",
    "            shorter_df = df_r\n",
    "            ml_long = True\n",
    "        else:\n",
    "            longer_df = df_r\n",
    "            shorter_df = df_ml_0\n",
    "\n",
    "        # Initialize counters\n",
    "        i = 0\n",
    "        j = 0\n",
    "\n",
    "        # Compare each row of both DataFrames\n",
    "        while i < len(longer_df) and j < len(shorter_df):\n",
    "            if not np.isclose(longer_df.loc[i, 'Actual'], shorter_df.loc[j, 'Actual'], atol=delta):\n",
    "                longer_df = longer_df.drop(i).reset_index(drop=True)\n",
    "                if ml_long:\n",
    "                    df_ml_1_df = df_ml_1.drop(i).reset_index(drop=True)\n",
    "                    df_ml_2_df = df_ml_2.drop(i).reset_index(drop=True)\n",
    "            else:\n",
    "                i += 2\n",
    "                j += 2\n",
    "\n",
    "        # Remove any extra rows from the longer DataFrame\n",
    "        longer_df = longer_df[:len(shorter_df)]\n",
    "        if ml_long:\n",
    "            df_ml_1 = df_ml_1[:len(shorter_df)]\n",
    "            df_ml_2 = df_ml_2[:len(shorter_df)]\n",
    "\n",
    "\n",
    "\n",
    "        # Print the final cleaned longer DataFrame\n",
    "        print(\"\\nCleaned Longer DataFrame:\")\n",
    "        print(longer_df)\n",
    "        '''\n",
    "        cumsum = 0\n",
    "        for i in range(len(df_r)):\n",
    "            t = df_r.loc[i, \"Actual\"]\n",
    "            cumsum += df_r.loc[i, \"Actual\"] - df_ml_0.loc[i, \"Actual\"]\n",
    "            \n",
    "        \n",
    "        print(cumsum)\n",
    "\n",
    "        # Sum up all column errors to get the total cumulative error\n",
    "\n",
    "        # Remove the identified rows from the longer DataFrame\n",
    "        df_merged = pd.merge(df_r, df_ml_0, left_index=True, right_index=True, how=\"left\", suffixes=(\"\", \"_ml\"))\n",
    "        df_merged = pd.merge(df_merged, df_ml_1, left_index=True, right_index=True, how=\"left\", suffixes=(\"\", \"_1_ml\"))\n",
    "        df_merged = pd.merge(df_merged, df_ml_2, left_index=True, right_index=True, how=\"left\", suffixes=(\"\", \"_2_ml\"))\n",
    "\n",
    "\n",
    "        # Remove right DataFrame's duplicate columns\n",
    "        columns_to_keep = [col for col in df_merged.columns if not col.endswith('_ml')]\n",
    "\n",
    "        # Keep only the required columns (excluding duplicates from the right DataFrame)\n",
    "        df_final = df_merged[columns_to_keep]\n",
    "        # Remove unnamed columns (columns with 'Unnamed' in their name)\n",
    "        df_final = df_final.loc[:, ~df_final.columns.str.contains('^Unnamed')]\n",
    "        #df_final.head()\n",
    "        #print(df_final)\n",
    "        \n",
    "        \n",
    "        df = df_final\n",
    "        \n",
    "        # COMB 1\n",
    "        # Selected models\n",
    "        if seg == \"pmx\" or seg == \"csz\":\n",
    "            forecast_columns = ['VECM_pred', 'LSTM_pred_[2, 4]']\n",
    "        elif seg == \"smx\":\n",
    "            forecast_columns = ['VECM_pred', 'LSTM_pred_[3, 4]']\n",
    "            \n",
    "        forecast_data = df[forecast_columns].to_numpy()\n",
    "\n",
    "\n",
    "        df['avg_1_pred'] = df[forecast_columns].mean(axis=1)\n",
    "        df['avg_1_res'] = df['Actual'] - df['avg_1_pred']\n",
    "\n",
    "\n",
    "        # Covariance matrix and eigenvectors\n",
    "        cov_matrix = np.cov(forecast_data, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "        # Get the eigenvector associated with the largest eigenvalue\n",
    "        largest_eigenvector = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "        eigenvector_weights = largest_eigenvector / np.sum(largest_eigenvector)\n",
    "\n",
    "        # Combine forecasts using the largest eigenvector\n",
    "        df['eigen_1_pred'] = np.dot(forecast_data, eigenvector_weights)\n",
    "        df['eigen_1_res'] = df['Actual'] - df['eigen_1_pred']\n",
    "        #print(df)\n",
    "\n",
    "\n",
    "        # COMB 2\n",
    "        # ALl models\n",
    "        # Prepare for Eigenvector-Based Combination\n",
    "        if seg == \"pmx\":\n",
    "            forecast_columns = ['VAR_pred', 'VECM_pred', 'ARIMA_pred', 'MLP_pred_[]', 'LSTM_pred_[]', \n",
    "                                'MLP_pred_[2]', 'LSTM_pred_[2]', 'MLP_pred_[2, 4]', 'LSTM_pred_[2, 4]']\n",
    "        elif seg == \"csz\":\n",
    "            forecast_columns = ['VAR_pred', 'VECM_pred', 'ARIMA_pred', 'MLP_pred_[]', 'LSTM_pred_[]', \n",
    "                                'MLP_pred_[4]', 'LSTM_pred_[4]', 'MLP_pred_[2, 4]', 'LSTM_pred_[2, 4]']     \n",
    "        elif seg == \"smx\":\n",
    "            forecast_columns = ['VAR_pred', 'VECM_pred', 'ARIMA_pred', 'MLP_pred_[]', 'LSTM_pred_[]', \n",
    "                                'MLP_pred_[2]', 'LSTM_pred_[2]', 'MLP_pred_[3, 4]', 'LSTM_pred_[3, 4]']       \n",
    "        forecast_data = df[forecast_columns].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "        # Compute the Simple Average of All Models\n",
    "        df['avg_2_pred'] = df[forecast_columns].mean(axis=1)\n",
    "        df['avg_2_res'] = df['Actual'] - df['avg_2_pred']\n",
    "\n",
    "\n",
    "        # Combine All Models using the Eigenvector-Based Combination\n",
    "        cov_matrix_all = np.cov(forecast_data, rowvar=False)\n",
    "        eigenvalues_all, eigenvectors_all = np.linalg.eig(cov_matrix_all)\n",
    "\n",
    "        # Get the eigenvector associated with the largest eigenvalue\n",
    "        largest_eigenvector_all = eigenvectors_all[:, np.argmax(eigenvalues_all)]\n",
    "        eigenvector_weights_all = largest_eigenvector_all / np.sum(largest_eigenvector_all)\n",
    "\n",
    "        # Combine forecasts using the largest eigenvector\n",
    "        df['eigen_2_pred'] = np.dot(forecast_data, eigenvector_weights_all)\n",
    "        df['eigen_2_res'] = df['Actual'] - df['eigen_2_pred']\n",
    "\n",
    "        #print(df)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # COMB 3: ALl Econometric models\n",
    "\n",
    "        #df = df_final.copy()\n",
    "        #print(df)\n",
    "\n",
    "        # Prepare for Eigenvector-Based Combination\n",
    "        forecast_columns = ['VAR_pred', 'VECM_pred', 'ARIMA_pred']\n",
    "        forecast_data = df[forecast_columns].to_numpy()\n",
    "\n",
    "        # Compute the Simple Average of All Models\n",
    "        df['avg_3_pred'] = df[forecast_columns].mean(axis=1)\n",
    "        df['avg_3_res'] = df['Actual'] - df['avg_3_pred']\n",
    "\n",
    "        # Combine All Models using the Eigenvector-Based Combination\n",
    "        cov_matrix_all = np.cov(forecast_data, rowvar=False)\n",
    "        eigenvalues_all, eigenvectors_all = np.linalg.eig(cov_matrix_all)\n",
    "\n",
    "        # Get the eigenvector associated with the largest eigenvalue\n",
    "        largest_eigenvector_all = eigenvectors_all[:, np.argmax(eigenvalues_all)]\n",
    "        eigenvector_weights_all = largest_eigenvector_all / np.sum(largest_eigenvector_all)\n",
    "\n",
    "        # Combine forecasts using the largest eigenvector\n",
    "        df['eigen_3_pred'] = np.dot(forecast_data, eigenvector_weights_all)\n",
    "        df['eigen_3_res'] = df['Actual'] - df['eigen_3_pred']\n",
    "\n",
    "        df_comb2 = df.copy()\n",
    "        #print(df)\n",
    "        \n",
    "        \n",
    "        # COMB 4: ALl ML models\n",
    "\n",
    "        #df = df_final.copy()\n",
    "        #print(df)\n",
    "\n",
    "\n",
    "        # Prepare for Eigenvector-Based Combination\n",
    "        if seg == \"pmx\":\n",
    "            forecast_columns = ['MLP_pred_[]', 'LSTM_pred_[]', \n",
    "                                'MLP_pred_[2]', 'LSTM_pred_[2]', 'MLP_pred_[2, 4]', 'LSTM_pred_[2, 4]']\n",
    "        elif seg == \"csz\":\n",
    "            forecast_columns = ['MLP_pred_[]', 'LSTM_pred_[]', \n",
    "                                'MLP_pred_[4]', 'LSTM_pred_[4]', 'MLP_pred_[2, 4]', 'LSTM_pred_[2, 4]']     \n",
    "        elif seg == \"smx\":\n",
    "            forecast_columns = ['MLP_pred_[]', 'LSTM_pred_[]', \n",
    "                                'MLP_pred_[2]', 'LSTM_pred_[2]', 'MLP_pred_[3, 4]', 'LSTM_pred_[3, 4]']  \n",
    "        forecast_data = df[forecast_columns].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "        # Compute the Simple Average of All Models\n",
    "        df['avg_4_pred'] = df[forecast_columns].mean(axis=1)\n",
    "        df['avg_4_res'] = df['Actual'] - df['avg_4_pred']\n",
    "\n",
    "\n",
    "        # Combine All Models using the Eigenvector-Based Combination\n",
    "        cov_matrix_all = np.cov(forecast_data, rowvar=False)\n",
    "        eigenvalues_all, eigenvectors_all = np.linalg.eig(cov_matrix_all)\n",
    "\n",
    "        # Get the eigenvector associated with the largest eigenvalue\n",
    "        largest_eigenvector_all = eigenvectors_all[:, np.argmax(eigenvalues_all)]\n",
    "        eigenvector_weights_all = largest_eigenvector_all / np.sum(largest_eigenvector_all)\n",
    "\n",
    "        # Combine forecasts using the largest eigenvector\n",
    "        df['eigen_4_pred'] = np.dot(forecast_data, eigenvector_weights_all)\n",
    "        df['eigen_4_res'] = df['Actual'] - df['eigen_4_pred']\n",
    "\n",
    "        df_comb2 = df.copy()\n",
    "        #print(df)\n",
    "        \n",
    "\n",
    "        df.to_csv(f'./mcs/{seg}_{hor}.csv', index=False, mode=\"a\")    \n",
    "\n",
    "\n",
    "\n",
    "        rw_rmses= []\n",
    "\n",
    "        avg_1_rmses = []\n",
    "        avg_1_maes = []\n",
    "        avg_1_mapes = []\n",
    "        avg_1_corr_dirs = []\n",
    "        eigen_1_rmses = []\n",
    "        eigen_1_maes = []\n",
    "        eigen_1_mapes = []\n",
    "        eigen_1_corr_dirs = []\n",
    "\n",
    "        avg_2_rmses = []\n",
    "        avg_2_maes = []\n",
    "        avg_2_mapes = []\n",
    "        avg_2_corr_dirs = []\n",
    "        eigen_2_rmses = []\n",
    "        eigen_2_maes = []\n",
    "        eigen_2_mapes = []\n",
    "        eigen_2_corr_dirs = []\n",
    "\n",
    "        avg_3_rmses = []\n",
    "        avg_3_maes = []\n",
    "        avg_3_mapes = []\n",
    "        avg_3_corr_dirs = []\n",
    "        eigen_3_rmses = []\n",
    "        eigen_3_maes = []\n",
    "        eigen_3_mapes = []\n",
    "        eigen_3_corr_dirs = []\n",
    "\n",
    "        avg_4_rmses = []\n",
    "        avg_4_maes = []\n",
    "        avg_4_mapes = []\n",
    "        avg_4_corr_dirs = []\n",
    "        eigen_4_rmses = []\n",
    "        eigen_4_maes = []\n",
    "        eigen_4_mapes = []\n",
    "        eigen_4_corr_dirs = []\n",
    "\n",
    "        num_fcs = len(df) // hor\n",
    "        for j in range(1):\n",
    "            i = j * hor\n",
    "            if j == 0:\n",
    "                last_value = None\n",
    "            else:\n",
    "                last_value = df[\"Actual\"].iloc[i-1]\n",
    "            act = df[\"Actual\"].iloc[i:i+hor]\n",
    "            print(act)\n",
    "            \n",
    "            rw_rmses.append(calculate_rmse(act, df[\"RW_pred\"].iloc[i:i+hor]))\n",
    "            \n",
    "            pred = df[\"avg_1_pred\"].iloc[i:i+hor]\n",
    "            avg_1_rmses.append(calculate_rmse(act,pred ))\n",
    "            avg_1_maes.append(calculate_mae(act, pred))\n",
    "            avg_1_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                avg_1_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "            \n",
    "            pred = df[\"eigen_1_pred\"].iloc[i:i+hor]   \n",
    "            eigen_1_rmses.append(calculate_rmse(act,pred ))\n",
    "            eigen_1_maes.append(calculate_mae(act, pred))\n",
    "            eigen_1_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                eigen_1_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "\n",
    "            pred = df[\"avg_2_pred\"].iloc[i:i+hor]\n",
    "            avg_2_rmses.append(calculate_rmse(act,pred ))\n",
    "            avg_2_maes.append(calculate_mae(act, pred))\n",
    "            avg_2_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                avg_2_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "            \n",
    "            pred = df[\"eigen_2_pred\"].iloc[i:i+hor]   \n",
    "            eigen_2_rmses.append(calculate_rmse(act,pred ))\n",
    "            eigen_2_maes.append(calculate_mae(act, pred))\n",
    "            eigen_2_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                eigen_2_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "\n",
    "            pred = df[\"avg_3_pred\"].iloc[i:i+hor]\n",
    "            avg_3_rmses.append(calculate_rmse(act,pred ))\n",
    "            avg_3_maes.append(calculate_mae(act, pred))\n",
    "            avg_3_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                avg_3_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "            \n",
    "            pred = df[\"eigen_3_pred\"].iloc[i:i+hor]   \n",
    "            eigen_3_rmses.append(calculate_rmse(act,pred ))\n",
    "            eigen_3_maes.append(calculate_mae(act, pred))\n",
    "            eigen_3_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                eigen_3_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "\n",
    "            pred = df[\"avg_4_pred\"].iloc[i:i+hor]\n",
    "            avg_4_rmses.append(calculate_rmse(act,pred ))\n",
    "            avg_4_maes.append(calculate_mae(act, pred))\n",
    "            avg_4_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                avg_4_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "            \n",
    "            pred = df[\"eigen_4_pred\"].iloc[i:i+hor]   \n",
    "            eigen_4_rmses.append(calculate_rmse(act,pred ))\n",
    "            eigen_4_maes.append(calculate_mae(act, pred))\n",
    "            eigen_4_mapes.append(calculate_mape(act, pred))\n",
    "            if last_value:\n",
    "                eigen_4_corr_dirs.append(calculate_corr_dir(act, pred, last_value))\n",
    "            \n",
    "\n",
    "        rw_rmse = np.mean(rw_rmses)\n",
    "\n",
    "        avg_1_rmse = np.mean(avg_1_rmses)\n",
    "        avg_1_mae = np.mean(avg_1_maes)\n",
    "        avg_1_mape = np.mean(avg_1_mapes)\n",
    "        avg_1_corr_dir = calculate_avg_dir_accuracy(avg_1_corr_dirs)\n",
    "        avg_1_red = calculate_rmse_reduction(rw_rmse, avg_1_rmse)\n",
    "                \n",
    "        eigen_1_rmse = np.mean(eigen_1_rmses)\n",
    "        eigen_1_mae = np.mean(eigen_1_maes)\n",
    "        eigen_1_mape = np.mean(eigen_1_mapes)\n",
    "        eigen_1_corr_dir = calculate_avg_dir_accuracy(eigen_1_corr_dirs)\n",
    "        eigen_1_red = calculate_rmse_reduction(rw_rmse, eigen_1_rmse)\n",
    "\n",
    "        avg_2_rmse = np.mean(avg_2_rmses)\n",
    "        avg_2_mae = np.mean(avg_2_maes)\n",
    "        avg_2_mape = np.mean(avg_2_mapes)\n",
    "        avg_2_corr_dir = calculate_avg_dir_accuracy(avg_2_corr_dirs)\n",
    "        avg_2_red = calculate_rmse_reduction(rw_rmse, avg_2_rmse)\n",
    "\n",
    "        eigen_2_rmse = np.mean(eigen_2_rmses)\n",
    "        eigen_2_mae = np.mean(eigen_2_maes)\n",
    "        eigen_2_mape = np.mean(eigen_2_mapes)\n",
    "        eigen_2_corr_dir = calculate_avg_dir_accuracy(eigen_2_corr_dirs)\n",
    "        eigen_2_red = calculate_rmse_reduction(rw_rmse, eigen_2_rmse)\n",
    "\n",
    "        avg_3_rmse = np.mean(avg_3_rmses)\n",
    "        avg_3_mae = np.mean(avg_3_maes)\n",
    "        avg_3_mape = np.mean(avg_3_mapes)\n",
    "        avg_3_corr_dir = calculate_avg_dir_accuracy(avg_3_corr_dirs)\n",
    "        avg_3_red = calculate_rmse_reduction(rw_rmse, avg_3_rmse)\n",
    "\n",
    "        eigen_3_rmse = np.mean(eigen_3_rmses)\n",
    "        eigen_3_mae = np.mean(eigen_3_maes)\n",
    "        eigen_3_mape = np.mean(eigen_3_mapes)\n",
    "        eigen_3_corr_dir = calculate_avg_dir_accuracy(eigen_3_corr_dirs)\n",
    "        eigen_3_red = calculate_rmse_reduction(rw_rmse, eigen_3_rmse)\n",
    "\n",
    "        avg_4_rmse = np.mean(avg_4_rmses)\n",
    "        avg_4_mae = np.mean(avg_4_maes)\n",
    "        avg_4_mape = np.mean(avg_4_mapes)\n",
    "        avg_4_corr_dir = calculate_avg_dir_accuracy(avg_4_corr_dirs)\n",
    "        avg_4_red = calculate_rmse_reduction(rw_rmse, avg_4_rmse)\n",
    "\n",
    "        eigen_4_rmse = np.mean(eigen_4_rmses)\n",
    "        eigen_4_mae = np.mean(eigen_4_maes)\n",
    "        eigen_4_mape = np.mean(eigen_4_mapes)\n",
    "        eigen_4_corr_dir = calculate_avg_dir_accuracy(eigen_4_corr_dirs)\n",
    "        eigen_4_red = calculate_rmse_reduction(rw_rmse, eigen_4_rmse)\n",
    "\n",
    "        # Prepare data for CSV\n",
    "        results = [\n",
    "            [seg, hor, 'avg_1', avg_1_rmse, avg_1_mae, avg_1_mape, avg_1_corr_dir, avg_1_red],\n",
    "            [seg, hor, 'eigen_1', eigen_1_rmse, eigen_1_mae, eigen_1_mape, eigen_1_corr_dir, eigen_1_red],\n",
    "            [seg, hor, 'avg_2', avg_2_rmse, avg_2_mae, avg_2_mape, avg_2_corr_dir, avg_2_red],\n",
    "            [seg, hor, 'eigen_2', eigen_2_rmse, eigen_2_mae, eigen_2_mape, eigen_2_corr_dir, eigen_2_red],\n",
    "            [seg, hor, 'avg_3', avg_3_rmse, avg_3_mae, avg_3_mape, avg_3_corr_dir, avg_3_red],\n",
    "            [seg, hor, 'eigen_3', eigen_3_rmse, eigen_3_mae, eigen_3_mape, eigen_3_corr_dir, eigen_3_red],\n",
    "            [seg, hor, 'avg_4', avg_4_rmse, avg_4_mae, avg_4_mape, avg_4_corr_dir, avg_4_red],\n",
    "            [seg, hor, 'eigen_4', eigen_4_rmse, eigen_4_mae, eigen_4_mape, eigen_4_corr_dir, eigen_4_red],\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame\n",
    "        columns = ['Segment', 'Horizon', 'Model', 'RMSE', 'MAE', 'MAPE', 'CorrDir', 'Reduction']\n",
    "        results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "        # Write to CSV\n",
    "        results_df.to_csv('model_metrics.csv', index=False, header=False, mode=\"a\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_comb1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
